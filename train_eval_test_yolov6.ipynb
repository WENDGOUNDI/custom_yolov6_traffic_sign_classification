{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect to google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlBXjYCMhO0_",
        "outputId": "890350dd-4331-4af7-f269-031b1f269263"
      },
      "id": "WlBXjYCMhO0_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to the Yolov6 main folder\n",
        "cd /content/drive/MyDrive/DL/Object_Detection/YOLOv6-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-Spr0ndhOyJ",
        "outputId": "eac98d7b-76c3-46ef-bbfc-9ada1a71745e"
      },
      "id": "V-Spr0ndhOyJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL/Object_Detection/YOLOv6-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list the Yolov6 main folder element\n",
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZeNlBFphOvn",
        "outputId": "60572d64-3546-4f14-e759-c45703e2db84"
      },
      "id": "nZeNlBFphOvn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/                        \u001b[01;34mdeploy\u001b[0m/           \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mconfigs\u001b[0m/                       \u001b[01;34mdocs\u001b[0m/             Untitled.ipynb\n",
            "\u001b[01;34mdata\u001b[0m/                          LICENSE           \u001b[01;34mweights\u001b[0m/\n",
            "\u001b[01;34mdata-20220705T081114Z-001\u001b[0m/     README.md         \u001b[01;34myolov6\u001b[0m/\n",
            "data-20220705T081114Z-001.zip  requirements.txt\n",
            "dataset.yaml                   \u001b[01;34mruns\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWNCzFD_hOsj",
        "outputId": "a39fb49a-18ec-4ea2-92d5-5c4acbf6de64"
      },
      "id": "CWNCzFD_hOsj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.64.0)\n",
            "Collecting addict>=2.4.0\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.0.4)\n",
            "Collecting onnx>=1.10.0\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 55.4 MB/s \n",
            "\u001b[?25hCollecting onnx-simplifier>=0.3.6\n",
            "  Downloading onnx-simplifier-0.3.10.tar.gz (14 kB)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.0.post2207010342-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.46.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.17.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.2.2)\n",
            "Collecting onnxoptimizer>=0.2.6\n",
            "  Downloading onnxoptimizer-0.2.7-cp37-cp37m-manylinux2014_x86_64.whl (498 kB)\n",
            "\u001b[K     |████████████████████████████████| 498 kB 68.5 MB/s \n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 66.7 MB/s \n",
            "\u001b[?25hCollecting onnxruntime>=1.11.1\n",
            "  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.11.1->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.6.1)\n",
            "Building wheels for collected packages: onnx-simplifier\n",
            "  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.10-py3-none-any.whl size=14811 sha256=d9ab01574ed9c5ca93bfb33eb1560408617d8e1765c60edc22d229150a326666\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/1c/e5/85fe0c71a3a655fd0082319f235dab0f60c129e1cc3d73f6c0\n",
            "Successfully built onnx-simplifier\n",
            "Installing collected packages: onnx, commonmark, rich, onnxruntime, onnxoptimizer, thop, PyYAML, onnx-simplifier, addict\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 addict-2.4.0 commonmark-0.9.1 onnx-1.12.0 onnx-simplifier-0.3.10 onnxoptimizer-0.2.7 onnxruntime-1.11.1 rich-12.4.4 thop-0.1.0.post2207010342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch library and check the availabilty of a GPU.\n",
        "# Here I a using Google Colab Tesla T4 GPU\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available() \n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "webgBH17hOp-",
        "outputId": "7ef37830-a50c-4748-fa56-634decf1f109"
      },
      "id": "webgBH17hOp-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training step"
      ],
      "metadata": {
        "id": "kjh8-xMc47r4"
      },
      "id": "kjh8-xMc47r4"
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --batch 16 --conf configs/yolov6s_finetune.py --data-path dataset.yaml --device 0 --epochs 10 --eval-interval 2"
      ],
      "metadata": {
        "id": "6Mzx7PlehOj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c21cef-cf10-4164-e46b-496b9282e28c"
      },
      "id": "6Mzx7PlehOj2",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1 GPU for training... \n",
            "training args are: Namespace(batch_size=16, check_images=False, check_labels=False, conf_file='configs/yolov6s_finetune.py', data_path='dataset.yaml', device='0', dist_url='env://', epochs=10, eval_final_only=False, eval_interval=2, gpu_count=0, heavy_eval_range=50, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', rank=-1, resume=False, save_dir='runs/train/exp14', workers=8, world_size=1)\n",
            "\n",
            "Train: Final numbers of valid images: 631/ labels: 631. \n",
            "0.0s for dataset initialization.\n",
            "Convert to COCO format\n",
            "\r  0% 0/100 [00:00<?, ?it/s]\r100% 100/100 [00:00<00:00, 90161.31it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/DL/Object_Detection/YOLOv6-main/data/annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 100/ labels: 100. \n",
            "0.0s for dataset initialization.\n",
            "Loading state_dict from ./weights/yolov6s.pt for fine-tuning...\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): Sequential(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): Sequential(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimSPPF(\n",
            "        (cv1): SimConv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (cv2): SimConv(\n",
            "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepPANNeck(\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): Sequential(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): Sequential(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer0): SimConv(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample0): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (reduce_layer1): SimConv(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (upsample1): Transpose(\n",
            "      (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (downsample2): SimConv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (downsample1): SimConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Training start...\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "  0% 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "       0/9     1.717     0.761     6.709     2.788: 100% 40/40 [01:05<00:00,  1.65s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:05<00:00,  1.39s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.34s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.78s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.32s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467\n",
            "Epoch: 0 | mAP@0.5: 0.1211823568273121 | mAP@0.50:0.95: 0.06999356428413823\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       1/9     1.452    0.5543     2.801     1.797: 100% 40/40 [01:05<00:00,  1.65s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:04<00:00,  1.14s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.48s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.28s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "Epoch: 1 | mAP@0.5: 0.4711595971210748 | mAP@0.50:0.95: 0.30302535058487967\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       2/9     1.524    0.5445      2.42     1.412: 100% 40/40 [01:06<00:00,  1.67s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:04<00:00,  1.13s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.715\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808\n",
            "Epoch: 2 | mAP@0.5: 0.6009810912573371 | mAP@0.50:0.95: 0.3706494985642539\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       3/9     1.445    0.4988     1.978     1.262: 100% 40/40 [01:04<00:00,  1.61s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:02<00:00,  1.35it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.95s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.48s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.477\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.507\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            "Epoch: 3 | mAP@0.5: 0.6620258312908412 | mAP@0.50:0.95: 0.4103437855188267\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       4/9     1.799    0.6124     1.988     1.244: 100% 40/40 [01:06<00:00,  1.66s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:03<00:00,  1.21it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.443\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            "Epoch: 4 | mAP@0.5: 0.6849986453430883 | mAP@0.50:0.95: 0.26292676674033993\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       5/9     1.806    0.6028     1.893     1.132: 100% 40/40 [01:03<00:00,  1.59s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:02<00:00,  1.36it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.47s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            "Epoch: 5 | mAP@0.5: 0.7300738287023149 | mAP@0.50:0.95: 0.25840615052305754\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       6/9     1.736    0.5869     1.753     1.127: 100% 40/40 [01:08<00:00,  1.72s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.81s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.43s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            "Epoch: 6 | mAP@0.5: 0.8387914648509185 | mAP@0.50:0.95: 0.521895685792683\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       7/9     1.639    0.5366     1.615     1.056: 100% 40/40 [01:05<00:00,  1.65s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:02<00:00,  1.43it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.60s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "Epoch: 7 | mAP@0.5: 0.839321206119173 | mAP@0.50:0.95: 0.4228207493890144\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       8/9     1.624    0.5261     1.627     1.029: 100% 40/40 [01:06<00:00,  1.66s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:02<00:00,  1.53it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.719\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.390\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "Epoch: 8 | mAP@0.5: 0.8505646547552322 | mAP@0.50:0.95: 0.5880175832694894\n",
            "\n",
            "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
            "       9/9      1.58    0.5103      1.56     1.011: 100% 40/40 [01:05<00:00,  1.65s/it]\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:02<00:00,  1.36it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp14/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.873\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
            "Epoch: 9 | mAP@0.5: 0.8732389149363554 | mAP@0.50:0.95: 0.46131725058567985\n",
            "\n",
            "Training completed in 0.206 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Step**"
      ],
      "metadata": {
        "id": "K8i08v734YA6"
      },
      "id": "K8i08v734YA6"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e6ef48d6",
      "metadata": {
        "id": "e6ef48d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899b56a4-825e-410c-d505-07bf7dfcb361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=32, conf_thres=0.001, data='dataset.yaml', device='0', half=False, img_size=640, iou_thres=0.65, name='exp', save_dir='runs/val/', task='val', weights='runs/train/exp14/weights/best_ckpt.pt')\n",
            "Loading checkpoint from runs/train/exp14/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Switch model to deploy modality.\n",
            "Model Summary: Params: 17.19M, Gflops: 44.08\n",
            "Val: Checking formats of labels with 2 process(es): \n",
            "100 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 100/100 [00:00<00:00, 915.23it/s]\n",
            "Convert to COCO format\n",
            "100% 100/100 [00:00<00:00, 125203.10it/s]\n",
            "Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/DL/Object_Detection/YOLOv6-main/data/annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 100/ labels: 100. \n",
            "0.3s for dataset initialization.\n",
            "Inferencing model in val datasets.: 100% 4/4 [00:03<00:00,  1.10it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "Average pre-process time: 0.21 ms\n",
            "Average inference time: 5.54 ms\n",
            "Average NMS time: 1.64 ms\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/val/exp2/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.40s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.720\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.687\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.768\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "Results saved to runs/val/exp2\n"
          ]
        }
      ],
      "source": [
        "!python tools/eval.py --data dataset.yaml  --weights runs/train/exp14/weights/best_ckpt.pt --device 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained model"
      ],
      "metadata": {
        "id": "zljlybYH4Kg2"
      },
      "id": "zljlybYH4Kg2"
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/infer.py --weights runs/train/exp14/weights/best_ckpt.pt --source /content/drive/MyDrive/DL/Object_Detection/YOLOv6-main/data/images/test/00894.jpg --yaml dataset.yaml --device 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIn-A8wAzVlp",
        "outputId": "f2d0e30d-948a-466a-cd15-52a1d0f06aeb"
      },
      "id": "CIn-A8wAzVlp",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, classes=None, conf_thres=0.25, device='0', half=False, hide_conf=False, hide_labels=False, img_size=640, iou_thres=0.45, max_det=1000, name='exp', project='runs/inference', save_img=True, save_txt=False, source='/content/drive/MyDrive/DL/Object_Detection/YOLOv6-main/data/images/test/00894.jpg', weights='runs/train/exp14/weights/best_ckpt.pt', yaml='dataset.yaml')\n",
            "Save directory already existed\n",
            "Loading checkpoint from runs/train/exp14/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 1/1 [00:00<00:00,  2.15it/s]\n",
            "Results saved to runs/inference/exp\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "train_eval_test_yolov6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}